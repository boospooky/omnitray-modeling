{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDE Modelling \n",
    "\n",
    "## Objectives \n",
    "* Make a model that describes cell growth and signalling at the scale of colonies \n",
    "\n",
    "## Model considerations \n",
    "* Species\n",
    "    1. Cell density \n",
    "    1. Nutrient density \n",
    "    1. Environmental AHL (considered equal to intracellular concentration)\n",
    "    1. Synthase / GFP\n",
    "    1. Repressor or degradase\n",
    "* Reactions \n",
    "    1. cell growth and diffusion \n",
    "        * Cells diffuse very slowly\n",
    "        * nutrient-dependent growth (from Liu et al 2011, Science) \n",
    "        $$  $$ \n",
    "    1. Transcriptional activation\n",
    "        * Basal protein expression -> scaled by repression? probably\n",
    "        * Activation by internal AHL \n",
    "        * Use Hill function $$H(A(t), n, k) = \\frac{A(t)^2}{k^n + A(t)^n}$$\n",
    "        * Activation term, with basal expression and expression rate x\n",
    "        $$X(A(t), n, k, b, x) = x\\frac{A(t)^2}{k^n + A(t)^n} + b$$\n",
    "    1. Transcriptional repression\n",
    "        * Assume activation is AND-like, meaning that repression trumps activation\n",
    "        * Use 'repression' Hill function $$H_n(R(t), n, k) = \\frac{k^n}{k^n + R(t)^n}$$\n",
    "        * Rather than considering protein concentrations within cells, calculate protein concentrations as produced by the bulk of cells. Expression is therefore proportional to cell density.\n",
    "    1. Dilution and degradation \n",
    "        * Assume that GFP/Synthase proteins are degradation tagged\n",
    "        * Degradase is not tagged, so does not have a degradation term\n",
    "    1. Diffusion \n",
    "        * Here, you're going to use convoultion of the diffusion kernel\n",
    "        * Diffusion in/out of cell is considered faster than spatial diffusion at these scales\n",
    "    1. Parameters\n",
    "        * We are also assuming, for the moment, that each time point is 6 minutes. Parameters with time dimensions shown below may use different units than the parameter from the cited paper.\n",
    "        * dx: Length modification of diffusion terms. In the compartmental model, diffusion is calculated via Ficks' first law, where the flux between two adjacent compartments is equal to the flux multiplied by the area of the interface between the components :  \n",
    "        $\\frac{\\mathrm{d} C}{\\mathrm{d} t} $ \n",
    "        in continuous form gives up \n",
    "        $\\Delta C = D \\frac{A}{V} \\frac{\\Delta C}{\\Delta x} = D \\frac{2.25 \\cdot 5 \\cdot \\mathrm{scale}^2 \\mathrm{mm}^2}{\\mathrm{scale} \\cdot 2.25^2 \\cdot 5 \\mathrm{mm}^3} \\frac{\\Delta C \\cdot \\mathrm{scale}}{2.25 \\mathrm{mm}} = \\frac{D \\Delta C \\mathrm{scale}^2}{2.25^2 \\mathrm{mm}^2}$. the dx parameter below is the symbol $A$ in this equation.\n",
    "        * Dc : Diffusion rate for cells. $7\\frac{mm^2}{min}$\n",
    "        * rc : Division rate of cells. $\\frac{1.14}{min}$\n",
    "        * Kn : Half-point of nutrient availability. 75\n",
    "        * Dn : Diffusion rate of nutrient. $28\\frac{mm^2}{min}$\n",
    "        * kn : Consumption rate of nutrient by cells\n",
    "        * Da : Diffusion rate of nutrient. $28\\frac{mm^2}{min}$\n",
    "        * xa : Synthesis rate of AHL. \n",
    "        * xs : Expression rate of protein. \n",
    "        * ha : Hill coefficient of AHL-inducible expression.\n",
    "        * ka : Half-point of AHL-inducible expression. \n",
    "        * pa : Degradation rate of AHL.\n",
    "        * leak : Leaky expression rate of protein. \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import string\n",
    "import scipy.integrate as itg\n",
    "import scipy.optimize as opt\n",
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.animation as anm\n",
    "import skimage.measure\n",
    "import numba\n",
    "import gc\n",
    "from multiprocessing import Pool, Process\n",
    "\n",
    "%load_ext line_profiler\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Discrete Laplacian\n",
    "\n",
    "In continuous form : \n",
    "$$ U_t = \\triangle U - \\lambda U $$\n",
    "\n",
    "In discrete form, for point $i$ : \n",
    "$$ \\Delta U_i = \\sum_{1 = w(i,j)}\\omega(i,j)(U_i - U_j) - \\lambda U_i $$\n",
    "\n",
    "Use discrete laplacian approximation w/o diagonals for grid spacing, so that we can have zero-flux  boundary conditions. \n",
    "\n",
    "$$ L = \n",
    " \\begin{pmatrix}\n",
    "  0 & 1 & 0 \\\\\n",
    "  1 & -4 & 1 \\\\\n",
    "  0 & 1 & 0 \n",
    " \\end{pmatrix} $$\n",
    "\n",
    "I use a convolution function to calculate the diffusion terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions used to define the arenas \n",
    "### Needs\n",
    "* read excel or csv files \n",
    "* rescaling arrays and contents \n",
    "* convert row/col to array index\n",
    "\n",
    "\n",
    "* disk function, projects circular areas onto an input grid \n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disk(A, center, radius):\n",
    "    h, w = A.shape\n",
    "    ind_mat = np.zeros((h, w, 2))\n",
    "    cx, cy = center\n",
    "    for i in range(h):\n",
    "        ind_mat[i,:,0] = np.power(np.arange(w) - cx, 2)\n",
    "    \n",
    "    for i in range(w):\n",
    "        ind_mat[:,i,1] = np.power(np.arange(h) - cy, 2)\n",
    "    \n",
    "    outmat = (ind_mat[:,:,0] + ind_mat[:,:,1]) < radius**2\n",
    "    return ndi.filters.gaussian_filter(outmat, radius/3)\n",
    "\n",
    "\n",
    "let_dict = dict(zip(string.ascii_uppercase, np.arange(0,26)))\n",
    "\n",
    "scale = 5\n",
    "scale_s = np.int(scale/2)\n",
    "n_w = 48 * scale\n",
    "n_h = 32 * scale\n",
    "\n",
    "species = 7 # rc_cells, cr_cells, nutrients, AHL_c, AHL_r, synthase_c, synthase_r\n",
    "tup = np.array([species, n_h, n_w])\n",
    "rc_i, cr_i, n_i, rhl_i, cin_i, rhli_i, cini_i = np.arange(species)\n",
    "\n",
    "# Make empty array\n",
    "A = np.zeros((species, n_h, n_w), dtype=np.float32,order='C') + 1e-7\n",
    "\n",
    "# Set initial conditions\n",
    "# Nutrients. All at 100\n",
    "A[n_i,:,:] = 100*np.ones((n_h, n_w), dtype=np.float32)\n",
    "\n",
    "tmax = 10\n",
    "t_points = np.int(tmax*10)\n",
    "\n",
    "# units : L = mm, T = minutes, concentration in nM = moles / mm^3\n",
    "# Da = 6 - 1.2 E-2\n",
    "#LEGACY\n",
    "# Params :    dx,                          Dc,    rc,  Kn,   Dn,   kn,  Da,  xa,  xs,  ha,  ka, \n",
    "p0 = np.array([np.power((scale/2.25),2),   5e-3, 6e-3,  75,  8e-3,  2, 8e-2, 1e3, 2e-0, 2.3, 40,    \n",
    "          # pa,   leak   od0\n",
    "             5e-5, 1e-8, 0.5], dtype=np.float32)\n",
    "\n",
    "# Params :    dx,                          Dc,    rc,  Kn,   Dn,    kn,  Da,  xa,  xs,  ha,  ka, \n",
    "p0 = np.array([np.power((scale/2.25),2),   1e-4, 6e-3,  75,  8e-3,  4, 2e-2, 1e3, 2e-0, 2.3, 40,\n",
    "# hC, kC, pa,   leak   od0\n",
    " 2.3, 40, 5e-5, 1e-8, 0.5], dtype=np.float32)\n",
    "\n",
    "# Change parameter values above. The function definitions inherit the parameter values defined here.\n",
    "dx, Dc,  rc,    Kn,  Dn,   kn, Da, xa, xs, hR, kR, hC, kC, pa, leak, od0 = p0\n",
    "\n",
    "#@numba.jit('void(float32[:,:,:],float32[:,:,:])', nopython=True, cache=True)\n",
    "@numba.jit(nopython=True, cache=True)\n",
    "def calc_diffusion(A, D):\n",
    "    # Middle\n",
    "    D[:,1:-1,1:-1] = A[:,1:-1, 2:] + A[:,1:-1, :-2] + A[:,:-2, 1:-1] + A[:,2:, 1:-1] - 4*A[:,1:-1, 1:-1]\n",
    "    # Edges\n",
    "    D[:,0,1:-1] = A[:,0, 2:] + A[:,0, :-2] + A[:,1, 1:-1] - 3*A[:,0, 1:-1]\n",
    "    D[:,-1,1:-1] = A[:,-1, 2:] + A[:,-1, :-2] + A[:,-2, 1:-1] - 3*A[:,-1, 1:-1]\n",
    "    D[:,1:-1,0] = A[:,2:,0] + A[:,:-2,0] + A[:,1:-1,1] - 3*A[:,1:-1,0]\n",
    "    D[:,1:-1,-1] = A[:,2:,-1] + A[:,:-2,-1] + A[:,1:-1,-2] - 3*A[:,1:-1,-1]\n",
    "    # Corners\n",
    "    D[:,0,0] = A[:,0,1] + A[:,1,0] - 2*A[:,0,0]\n",
    "    D[:,-1,0] = A[:,-1,1] + A[:,-2,0] - 2*A[:,-1,0]\n",
    "    D[:,0,-1] = A[:,0,-2] + A[:,1,-1] - 2*A[:,0,-1]\n",
    "    D[:,-1,-1] = A[:,-1,-2] + A[:,-2,-1] - 2*A[:,-1,-1]\n",
    "\n",
    "#@numba.jit('float32[:,:](float32[:,:],float32,float32)',nopython=True, cache=True)\n",
    "@numba.jit(nopython=True, cache=True)\n",
    "def hill(a, n, k):\n",
    "    h_ma = 1 - (1 / (1 + (a/k)**n))\n",
    "    return h_ma\n",
    "\n",
    "#@numba.jit('float32[:,:](float32[:,:],float32,float32)',nopython=True, cache=True)\n",
    "@numba.jit(nopython=True, cache=True)\n",
    "def hillN(a, n, k):\n",
    "    return 1 / (1 + (a/k)**n)\n",
    "\n",
    "#@numba.jit('void(float32[:,:,:],float32[:,:,:],float32[:,:,:],float32[:,:])',nopython=True, cache=True)\n",
    "@numba.jit(nopython=True, cache=True)\n",
    "def calc_f(y, d_y, diff_terms, nut_avail, p0):\n",
    "    dx, Dc,  rc,    Kn,  Dn,   kn, Da, xa, xs, hR, kR, hC, kC, pa, leak, od = p0\n",
    "    calc_diffusion(y, diff_terms)\n",
    "    \n",
    "    # Growth term\n",
    "    nut_avail[:] = hill(y[n_i,:,:], 2, Kn)\n",
    "    \n",
    "    d_y[rc_i,:,:] = (dx)*Dc*diff_terms[rc_i,:,:] + rc * nut_avail * y[rc_i,:,:]\n",
    "    d_y[cr_i,:,:] = (dx)*Dc*diff_terms[cr_i,:,:] + rc * nut_avail * y[cr_i,:,:]\n",
    "    d_y[n_i,:,:] = (dx)*Dn*diff_terms[n_i,:,:] - kn * nut_avail * (y[rc_i,:,:] + y[cr_i,:,:])\n",
    "    d_y[rhl_i,:,:] = (dx)*Da*diff_terms[rhl_i,:,:] + xa * y[rhli_i,:,:]*y[cr_i,:,:] - pa * y[rhl_i,:,:]\n",
    "    d_y[cin_i,:,:] = (dx)*Da*diff_terms[cin_i,:,:] + xa * y[cini_i,:,:]*y[rc_i,:,:] - pa * y[cin_i,:,:]\n",
    "    d_y[rhli_i,:,:] = (dx)*Dc*diff_terms[rhli_i,:,:] + xs * y[cr_i,:,:] * (hill(y[cin_i,:,:], hR, kR) + leak) * nut_avail\n",
    "    d_y[cini_i,:,:] = (dx)*Dc*diff_terms[cini_i,:,:] + xs * y[rc_i,:,:] * (hill(y[rhl_i,:,:], hC, kC) + leak) * nut_avail\n",
    "    \n",
    "\n",
    "# ODE definition\n",
    "#@numba.jit('float32[:](float32[:],float32[:],float32[:,:,:],float32[:,:,:],float32[:,:])', nopython=True)\n",
    "@numba.jit(nopython=True)\n",
    "def f(y, t, d_y, diff_terms, nut_avail, p0):\n",
    "    \n",
    "    y.shape = (species, n_h, n_w)\n",
    "    calc_f(y, d_y, diff_terms, nut_avail, p0)\n",
    "    \n",
    "    return d_y.flatten()\n",
    "\n",
    "def f_ivp(t, y, d_y, diff_terms, nut_avail, p0):\n",
    "    \n",
    "    y.shape = (species, n_h, n_w)\n",
    "    calc_f(y, d_y, diff_terms, nut_avail, p0)\n",
    "    \n",
    "    return d_y.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_omnitray(rc_spots, cr_spots, ahl_spots, p0, tmax=tmax, A=A.copy()):\n",
    "    \n",
    "    dx, Dc,  rc,    Kn,  Dn,   kn, Da, xa, xs, hR, kR, hC, kC, pa, leak, od = p0\n",
    "    \n",
    "    t = np.linspace(0,tmax,t_points,dtype=np.float32)\n",
    "\n",
    "    od0 = od\n",
    "    \n",
    "    rc_cells = np.zeros((n_h, n_w), dtype=np.float32)\n",
    "    for center in rc_spots:\n",
    "        rc_cells += disk(rc_cells, scale*np.array(center), scale_s)*od0\n",
    "\n",
    "    cr_cells = np.zeros((n_h, n_w), dtype=np.float32)\n",
    "    for center in cr_spots:\n",
    "        cr_cells += disk(cr_cells, scale*np.array(center), scale_s)*od0\n",
    "        \n",
    "    ahl_drops = np.zeros((n_h, n_w), dtype=np.float32)\n",
    "    for center in ahl_spots:\n",
    "        ahl_drops += disk(ahl_drops, scale*np.array(center), scale_s)*od0\n",
    "\n",
    "    # Set initial conditions\n",
    "    # rc_ells. Spotted according to the echo pick lists\n",
    "    A[0,:,:] += rc_cells\n",
    "\n",
    "    # cr_ells. Spotted according to the echo pick lists\n",
    "    A[1,:,:] += cr_cells\n",
    "\n",
    "    # Blur to make smooth colonies. This is basically cosmetic\n",
    "    #A[0,:,:] = ndi.filters.gaussian_filter(A[0,:,:], scale_s)\n",
    "    #A[1,:,:] = ndi.filters.gaussian_filter(A[1,:,:], scale_s)\n",
    "\n",
    "    # Nutrients. All at 100\n",
    "    #A[2,:,:] = 100*np.ones((n_h, n_w), dtype=np.float32)\n",
    "\n",
    "    # External rhl AHL.\n",
    "    #A[3,:,:] = np.zeros((n_h, n_w))\n",
    "\n",
    "    # External cin AHL.\n",
    "    A[4,:,:] += ahl_drops * 2.5e3\n",
    "\n",
    "    # cini\n",
    "    #A[5,:,:] = np.zeros((n_h, n_w))\n",
    "\n",
    "    # rhili\n",
    "    #A[6,:,:] = np.zeros((n_h, n_w))\n",
    "\n",
    "    args=(np.zeros(A.shape, dtype=np.float32,order='C'), \n",
    "          np.zeros(A.shape, dtype=np.float32,order='C'), \n",
    "          np.zeros(A.shape[1:], dtype=np.float32,order='C'), \n",
    "          p0)\n",
    "    A.shape = n_h*n_w*species\n",
    "    print('Starting')\n",
    "    #out = itg.odeint(f, A, t, args=args, atol=1e-6)\n",
    "    f_lambda = lambda t, y : f_ivp(t, y, *args)\n",
    "    out = itg.solve_ivp(f_lambda, [0, tmax], A, vectorized=True, t_eval=np.arange(tmax))\n",
    "    out.shape = (t_points, species, n_h, n_w)\n",
    "    print('DONE')\n",
    "    return out\n",
    "\n",
    "\n",
    "fn_base = \"/home/jmp/data/echo_files/20170829_circuit/combo/20170829_combo_ST{}.csv\"\n",
    "fnames = [fn_base.format(strain) \n",
    "          for strain in [3,4]\n",
    "         ]\n",
    "ahl_fn = \"/home/jmp/data/echo_files/20170829_circuit/AHL/20170829_combo_Cin AHL.csv\"\n",
    "\n",
    "#out = sim_omnitray(4, fnames[0], fnames[1], ahl_fn, p0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a look at one frame\n",
    "out.resize((t_points,species,n_h,n_w))\n",
    "\n",
    "print(out.shape)\n",
    "\n",
    "plt.close('all')\n",
    "fig, axs = plt.subplots(1,species, figsize=(19,5))\n",
    "for i in np.arange(species):\n",
    "    ax = axs[i]\n",
    "    img = ax.imshow(out[-1,i,:,:], interpolation='none')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    cbar = fig.colorbar(mappable=img, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t_i = np.arange(im_t)[colony_mean[:,0].max() == colony_mean[:,0]]\n",
    "masks, ls = skimage.measure.label(\n",
    "    np.logical_xor(im_arr[t_i, 0, :, :] > 0.12, \n",
    "                   im_arr[t_i, 1, :, :] > 0.12), \n",
    "    connectivity=1, \n",
    "    return_num=True)\n",
    "labels_vec[t_i] = labels\n",
    "plt.imshow(masks[0])\n",
    "print(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "DONE\n",
      "Starting\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5fa30431552f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#    res = p.map(wrapper, fn_inputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0ma_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-5fa30431552f>\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0movernight_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mburn_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0movernight_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0movernight_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_omnitray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mahl_spots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0movernight_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mexp_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mexp_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-4a7fa5918306>\u001b[0m in \u001b[0;36msim_omnitray\u001b[0;34m(rc_spots, cr_spots, ahl_spots, p0, tmax, A)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m#out = itg.odeint(f, A, t, args=args, atol=1e-6)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mf_lambda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mf_ivp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve_ivp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_lambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DONE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/ipykernel_py3/lib/python3.6/site-packages/scipy/integrate/_ivp/ivp.py\u001b[0m in \u001b[0;36msolve_ivp\u001b[0;34m(fun, t_span, y0, method, t_eval, dense_output, events, vectorized, **options)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/ipykernel_py3/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Try out FunctionAnimation approach\n",
    "fn_base = \"/home/jmp/data/echo_files/20170829_circuit/no AiiA/20170829_{}{}_ST{}.csv\"\n",
    "fnames = [\n",
    "           [\n",
    "              fn_base.format(letter, space, strain) \n",
    "              for space in [3]\n",
    "              for strain in [4, 3]\n",
    "            ]\n",
    "          for letter in ['a', 'b', 'c']\n",
    "         ]\n",
    "\n",
    "ahl_fn = \"/home/jmp/data/echo_files/20170829_circuit/AHL/20170829_abc3_Cin AHL.csv\"\n",
    "mat = pd.read_csv(ahl_fn)\n",
    "well_strs = list(mat[['    Destination Well']].values[:,0])\n",
    "ahl_centers = [(int(w[1:]), let_dict[w[:1]]) for w in well_strs]\n",
    "\n",
    "\n",
    "dest_wells = []\n",
    "for batch in fnames:\n",
    "    batch_list = []\n",
    "    for fn in batch:\n",
    "        mat = pd.read_csv(fn)\n",
    "        well_strs = list(mat[['    Destination Well']].values[:,0])\n",
    "        colony_centers = [(int(w[1:]), let_dict[w[:1]]) for w in well_strs]\n",
    "        batch_list.append(colony_centers)\n",
    "    dest_wells.append(batch_list)\n",
    "\n",
    "fn_inputs = []\n",
    "for i in range(3):\n",
    "    fn_inputs.append(dest_wells[i] + [ahl_centers, p0])\n",
    "\n",
    "def wrapper(p):\n",
    "    rc_spots, cr_spots, ahl_spots, p0 = p\n",
    "    burn_in = sim_omnitray(rc_spots, cr_spots, [], p0, tmax=18*60, A=A.copy())\n",
    "    overnight_t = burn_in.t\n",
    "    overnight_y = burn_in.y.T\n",
    "    overnight_y.shape = (len(overnight_t), species, n_h, n_w)\n",
    "    out = sim_omnitray([], [], ahl_spots, p0, A=overnight_y[-1,:,:,:], tmax=4*24*60)\n",
    "    exp_t = out.t\n",
    "    exp_y = out.y.T\n",
    "    exp_y.shape = (len(exp_t), species, n_h, n_w)\n",
    "    out = np.concatenate((overnight_y, exp_y), axis=0)\n",
    "    t_vec = np.concatenate((overnight_t, exp_t))\n",
    "    return exp_y, exp_t\n",
    "    \n",
    "#with Pool(3) as p:\n",
    "#    res = p.map(wrapper, fn_inputs)\n",
    "\n",
    "a_out = wrapper(fn_inputs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_movie(out, t, fn):\n",
    "\n",
    "    plt.close('all')\n",
    "\n",
    "    indx = cin_i\n",
    "    if len(t) < 50:\n",
    "        frames = len(t)\n",
    "    else:\n",
    "        frames = 50\n",
    "    view_masks = True\n",
    "\n",
    "    t_points, s, h, w = out.shape\n",
    "    # First set up the figure, the axis, and the plot element we want to animate\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    im_arr = out[::np.int(t_points/frames),:,:,:]\n",
    "    gc.collect()\n",
    "    t, s, h, w = im_arr.shape\n",
    "    blank_array = np.zeros([n_h, n_w])\n",
    "    if view_masks:\n",
    "        vmax = 7\n",
    "        vmin = 0\n",
    "    else:\n",
    "        vmax = im_arr[:,indx,:,:].max()\n",
    "        vmin = im_arr[:,indx,:,:].min()\n",
    "    im = plt.imshow(blank_array, animated=True, vmax=vmax, vmin=vmin, interpolation='none')\n",
    "\n",
    "    # initialization function: plot the background of each frame\n",
    "    def init():\n",
    "        im.set_array(blank_array)\n",
    "        return im,\n",
    "\n",
    "    # animation function.  This is called sequentially\n",
    "    def animate(i):\n",
    "        if view_masks:\n",
    "            mask, labls = skimage.measure.label(\n",
    "                np.logical_xor(im_arr[i, cr_i, :, :] > 0.05, im_arr[i, rc_i, :, :] > 0.05),\n",
    "                        return_num=True, connectivity=1) \n",
    "            im.set_array(mask)    \n",
    "        else:\n",
    "            im.set_array(im_arr[i, indx, :, :] + im_arr[i, indx-1, :, :] )\n",
    "            #im.set_array(im_arr[i, indx, :, :])\n",
    "        return im,\n",
    "\n",
    "    # call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "    anim = anm.FuncAnimation(fig, animate, interval=50, frames=frames)\n",
    "\n",
    "\n",
    "    # Set up formatting for the movie files\n",
    "    #Writer = anm.writers['ffmpeg_file']\n",
    "    #writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=900, extra_args=['-vcodec', 'libx264'])\n",
    "\n",
    "    # save the animation as an mp4.  This requires ffmpeg or mencoder to be\n",
    "    # installed.  The extra_args ensure that the x264 codec is used, so that\n",
    "    # the video can be embedded in html5.  You may need to adjust this for\n",
    "    # your system: for more information, see\n",
    "    # http://matplotlib.sourceforge.net/api/animation_api.html\n",
    "    #anim.save('animation_{}.mp4'.format(fn), extra_args=['-vcodec', 'libx264'], dpi=50, writer=writer)\n",
    "    #plt.close('all')\n",
    "\n",
    "\n",
    "    #anim.save('animation_{}.mp4'.format(fn), writer=writer)\n",
    "    plt.close('all')\n",
    "    return anim\n",
    "    #HTML(anim.to_html5_video())\n",
    "    \n",
    "out_names = [\"a\", \"b\", \"c\"]\n",
    "out, t = a_out\n",
    "anim = write_movie(out, t, out_names[i])\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = pd.read_csv('20170829_pos1_wCtime.csv')\n",
    "cols = jd.columns\n",
    "data_cols = cols[3:9]\n",
    "m1, m2 = jd[data_cols[::2]].dropna(axis=0).T.values.max(), jd[data_cols[1::2]].dropna(axis=0).T.values.max()\n",
    "plt.figure(figsize=(20,8))\n",
    "clean_fit_dict = dict()\n",
    "for col in data_cols[::2]:\n",
    "    y, t = list(jd[[col, 'Time elapsed']].dropna(axis=0).T.values)\n",
    "    y = (y-y.min())/(m1-y.min())\n",
    "    plt.plot(t, y,'.', label=col)\n",
    "    fit = np.polyfit(t, y, 5)\n",
    "    fitfn = np.poly1d(fit)\n",
    "    clean_fit_dict[col] = fitfn\n",
    "    plt.plot(t, fitfn(t),'k')\n",
    "    \n",
    "for col in data_cols[1::2]:\n",
    "    y, t = list(jd[[col, 'Time elapsed']].dropna(axis=0).T.values)\n",
    "    y = (y-y.min())/(m2-y.min())\n",
    "    plt.plot(t, y,'.', label=col)\n",
    "    fit = np.polyfit(t, y, 5)\n",
    "    fitfn = np.poly1d(fit)\n",
    "    clean_fit_dict[col] = fitfn\n",
    "    plt.plot(t, fitfn(t),'k')    \n",
    "    \n",
    "clean_fit_vec = [clean_fit_dict[key] for key in data_cols]\n",
    "\n",
    "plt.plot([0, 70], [0.18, 0.18], '--k')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traces = get_traces(out)\n",
    "#print(traces.shape)\n",
    "#for spec in range(species):\n",
    "#    plt.plot(traces[1000::10,spec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_traces(out):\n",
    "    t, s, h, w = out.shape\n",
    "    colony_mean = np.zeros((t, s))\n",
    "    for t_i in np.arange(t):\n",
    "        masks, n_l = skimage.measure.label(\n",
    "            np.logical_xor(out[t_i, 0, :, :] > 0.05, \n",
    "                           out[t_i, 1, :, :] > 0.05), \n",
    "            connectivity=1, \n",
    "            return_num=True)\n",
    "        for l in range(0,s,2):\n",
    "            colony_mean[t_i, l] = np.mean((masks==(l+1))*(out[t_i, cini_i,:,:]))\n",
    "        for l in range(1,s,2):\n",
    "            colony_mean[t_i, l] = np.mean((masks==(l+1))*(out[t_i, rhli_i,:,:]))\n",
    "    return colony_mean\n",
    "\n",
    "def sim_wrapper(p_in):\n",
    "    xa, xs, hR, kR, hC, kC, pa, leak, od = p_in\n",
    "    dx, Dc,  rc,    Kn,  Dn,   kn, Da = 2.25/np.power(scale,2),   2e-3, 6e-3,  75,  4e-1,  2, 4e-1\n",
    "    p_in = dx, Dc,  rc,    Kn,  Dn,   kn, Da, xa, xs, hR, kR, hC, kC, pa, leak, od\n",
    "    return wrapper((dest_wells[0][0], dest_wells[0][1], ahl_centers, p_in))\n",
    "\n",
    "def residuals(p_in):\n",
    "    y, t = sim_wrapper(p_in)\n",
    "    sim_traces = get_traces(y)\n",
    "    res = 0\n",
    "    for lab in range(6):\n",
    "        data_trace = clean_fit_vec[lab](t/60)\n",
    "        res += np.sum(np.power(sim_traces[:,lab] - data_trace, 2))\n",
    "    return res\n",
    "\n",
    "p_0 = xa, xs, hR, kR, hC, kC, pa, leak, od0\n",
    "opt_out = opt.minimize(residuals, p_0)\n",
    "print(opt_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_out.x - p_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
