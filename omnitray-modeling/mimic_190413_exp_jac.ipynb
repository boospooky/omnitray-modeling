{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDE Modelling Mimic of 190413 experiment\n",
    "\n",
    "## Objectives \n",
    "* Microscope movie was performed on 190413 that simply observed growth of a constitutively fluorescent strain on agar pads, varying in pad size and cell occupation\n",
    "* Simulate each of the experimental setups executed\n",
    "* eventually build into a fitting routine\n",
    "\n",
    "## Model considerations \n",
    "* Species\n",
    "    1. Cell density (sender and pulse cells)\n",
    "    1. Nutrient density \n",
    "    1. mScarlet\n",
    "* Reactions \n",
    "    1. cell growth and diffusion \n",
    "        * Cells diffuse very slowly\n",
    "        * nutrient-dependent growth (from Liu et al 2011, Science) \n",
    "        $$  $$ \n",
    "    1. Constitutive fluorescence\n",
    "        * Basal protein expression \n",
    "        * initial protein concentration set to fixed point of max nutrient\n",
    "    1. Dilution and degradation \n",
    "        * Assume that all proteins are degradation tagged\n",
    "    1. Diffusion \n",
    "        * Here, you're going to use convoultion of the diffusion kernel\n",
    "        * Diffusion in/out of cell is considered faster than spatial diffusion at these scales\n",
    "    1. Parameters\n",
    "        * We are also assuming, for the moment, that each time point is 6 minutes. Parameters with time dimensions shown below may use different units than the parameter from the cited paper.\n",
    "        * dx: Length modification of diffusion terms. In the compartmental model, diffusion is calculated via Ficks' first law, where the flux between two adjacent compartments is equal to the flux multiplied by the area of the interface between the components :  \n",
    "        $\\frac{\\mathrm{d} C}{\\mathrm{d} t} $ \n",
    "        in continuous form gives up \n",
    "        $\\Delta C = D \\frac{A}{V} \\frac{\\Delta C}{\\Delta x} = D \\frac{2.25 \\cdot 5 \\cdot \\mathrm{scale}^2 \\mathrm{mm}^2}{\\mathrm{scale} \\cdot 2.25^2 \\cdot 5 \\mathrm{mm}^3} \\frac{\\Delta C \\cdot \\mathrm{scale}}{2.25 \\mathrm{mm}} = \\frac{D \\Delta C \\mathrm{scale}^2}{2.25^2 \\mathrm{mm}^2}$. the dx parameter below is the symbol $A$ in this equation.\n",
    "        * Dc : Diffusion rate for cells. $7\\frac{mm^2}{min}$\n",
    "        * rc : Division rate of cells. $\\frac{1.14}{min}$\n",
    "        * Kn : Half-point of nutrient availability. 75\n",
    "        * Dn : Diffusion rate of nutrient. $28\\frac{mm^2}{min}$\n",
    "        * kn : Consumption rate of nutrient by cells\n",
    "        * Da : Diffusion rate of nutrient. $28\\frac{mm^2}{min}$\n",
    "        * xs : Expression rate of protein. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# from __future__ import division, print_function\n",
    "\n",
    "import itertools as itt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import string\n",
    "import selenium\n",
    "import scipy.integrate as itg\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['animation.ffmpeg_path'] = '/usr/bin/ffmpeg' # Add the path of ffmpeg here!!\n",
    "\n",
    "import matplotlib.animation as anm\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import numba\n",
    "# import gc\n",
    "import emcee\n",
    "\n",
    "from multiprocessing import Pool, Process, cpu_count\n",
    "\n",
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler\n",
    "import timeit\n",
    "\n",
    "# from IPython.display import HTML\n",
    "\n",
    "pad_times_df = pd.read_csv('pad_times.csv')\n",
    "pad_times_df = pad_times_df.loc[(pad_times_df.frame>=5)&(pad_times_df.frame<41),:]\n",
    "\n",
    "# rc = {'lines.linewidth': 2, \n",
    "#       'axes.labelsize': 18, \n",
    "#       'axes.titlesize': 24, \n",
    "#       'xtick.labelsize': 18, \n",
    "#       'ytick.labelsize': 18, \n",
    "#       'legend.fontsize': 18,\n",
    "#       'axes.facecolor': 'DFDFE5'}\n",
    "\n",
    "# sns.set_context('paper', rc=rc)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Discrete Laplacian\n",
    "\n",
    "In continuous form : \n",
    "$$ U_t = \\triangle U - \\lambda U $$\n",
    "\n",
    "In discrete form, for point $i$ : \n",
    "$$ \\Delta U_i = \\sum_{1 = w(i,j)}\\omega(i,j)(U_i - U_j) - \\lambda U_i $$\n",
    "\n",
    "Use discrete laplacian approximation w/o diagonals for grid spacing, so that we can have zero-flux  boundary conditions. \n",
    "\n",
    "$$ L = \n",
    " \\begin{pmatrix}\n",
    "  0 & 1 & 0 \\\\\n",
    "  1 & -4 & 1 \\\\\n",
    "  0 & 1 & 0 \n",
    " \\end{pmatrix} $$\n",
    "\n",
    "This is achieved though a bunch of subtractions between offset arrays.\n",
    "\n",
    "Attempt fitting w/o crowding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions used to define the arenas \n",
    "### Needs\n",
    "* read excel or csv files \n",
    "* rescaling arrays and contents \n",
    "* convert row/col to array index\n",
    "\n",
    "\n",
    "* disk function, projects circular areas onto an input grid \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try rewriting into class-based approach to simulation to speed up fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@numba.jit('void(float32[:,:,:],float32[:,:,:])', nopython=True, cache=True)\n",
    "@numba.jit(nopython=True, cache=True)\n",
    "def calc_diffusion(A, D):\n",
    "    # Middle\n",
    "    D[:,1:-1,1:-1] = A[:,1:-1, 2:] + A[:,1:-1, :-2] + A[:,:-2, 1:-1] + A[:,2:, 1:-1] - 4*A[:,1:-1, 1:-1]\n",
    "    # Edges\n",
    "    D[:,0,1:-1] = A[:,0, 2:] + A[:,0, :-2] + A[:,1, 1:-1] - 3*A[:,0, 1:-1]\n",
    "    D[:,-1,1:-1] = A[:,-1, 2:] + A[:,-1, :-2] + A[:,-2, 1:-1] - 3*A[:,-1, 1:-1]\n",
    "    D[:,1:-1,0] = A[:,2:,0] + A[:,:-2,0] + A[:,1:-1,1] - 3*A[:,1:-1,0]\n",
    "    D[:,1:-1,-1] = A[:,2:,-1] + A[:,:-2,-1] + A[:,1:-1,-2] - 3*A[:,1:-1,-1]\n",
    "    # Corners\n",
    "    D[:,0,0] = A[:,0,1] + A[:,1,0] - 2*A[:,0,0]\n",
    "    D[:,-1,0] = A[:,-1,1] + A[:,-2,0] - 2*A[:,-1,0]\n",
    "    D[:,0,-1] = A[:,0,-2] + A[:,1,-1] - 2*A[:,0,-1]\n",
    "    D[:,-1,-1] = A[:,-1,-2] + A[:,-2,-1] - 2*A[:,-1,-1]\n",
    "\n",
    "#@numba.jit('float32[:,:](float32[:,:],float32,float32)',nopython=True, cache=True)\n",
    "@numba.jit(nopython=True, cache=True)\n",
    "def hill(a, n, k):\n",
    "    h_ma = 1 - (1 / (1 + (a/k)**n))\n",
    "    return h_ma\n",
    "\n",
    "@numba.jit(nopython=True, cache=True)\n",
    "def dhillda(a, n, k):\n",
    "    h_ma = (n/k)*((a/k)**(n-1))*(1 / (1 + (a/k)**n)**2)\n",
    "    return h_ma\n",
    "\n",
    "#@numba.jit('float32[:,:](float32[:,:],float32,float32)',nopython=True, cache=True)\n",
    "@numba.jit(nopython=True, cache=True)\n",
    "def hillN(a, n, k):\n",
    "    return 1 / (1 + (a/k)**n)\n",
    "\n",
    "# @numba.jit(cache=True)\n",
    "def f_ivp(t, y, d_y, diff_terms, nut_avail, p0, dims, calc_f):\n",
    "    species, n_h, n_w, scale= dims\n",
    "    y.shape = (species, n_h, n_w)\n",
    "    calc_f(y, d_y, diff_terms, nut_avail, p0)\n",
    "    y.shape = species*n_h*n_w\n",
    "    return d_y.flatten()\n",
    "\n",
    "class FIVP(object):\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "\n",
    "    def f_ivp(self, t, y):\n",
    "        return f_ivp(t, y, *self.args)\n",
    "\n",
    "def wrapper(dims, p0, initial_array, t_eval, atol, rtol, calc_f, jac):\n",
    "#     print(solver)\n",
    "    species, n_h, n_w, scale = dims\n",
    "    args=(np.zeros((species, n_h, n_w), dtype=np.float32,order='C'), \n",
    "          np.zeros((species, n_h, n_w), dtype=np.float32,order='C'), \n",
    "          np.zeros((n_h, n_w), dtype=np.float32,order='C'), \n",
    "          p0, dims, calc_f)\n",
    "    initial_array.shape = (n_h*n_w*species,)\n",
    "    fivp_obj = FIVP(args)\n",
    "#     t_eval = t_eval - t_eval.min()\n",
    "    out = itg.solve_ivp(fivp_obj.f_ivp, [t_eval.min(), t_eval.max()], initial_array.copy(), \n",
    "                        vectorized=True, method=\"BDF\", dense_output=True,\n",
    "                        atol=atol, rtol=rtol, \n",
    "                        t_eval=t_eval, \n",
    "                        jac=jac)\n",
    "    exp_t = out.t\n",
    "    exp_y = out.y.T\n",
    "    exp_y.shape = (len(exp_t), species, n_h, n_w)\n",
    "#     print(\"nfev:{} njev:{}\".format(out.nfev, out.njev))\n",
    "    return exp_y, exp_t\n",
    "\n",
    "# @numba.jit(cache=True)\n",
    "def prep_pad_helper(scale, pad, frame):\n",
    "    mask_fn_tmpl = 'worker_outputs/initial_frame_masks/pad_{}_frame_{}.tif'\n",
    "    img_fn = mask_fn_tmpl.format(pad,frame)\n",
    "    init_cells = skimage.io.imread(img_fn)\n",
    "    scale_factor = (scale/4500)/(2.475/4)\n",
    "    scaled_init = skimage.transform.rescale((init_cells>1).astype(np.float32), \n",
    "                                            scale_factor, \n",
    "                                            order=0, \n",
    "                                            mode='constant', \n",
    "                                            multichannel=False,\n",
    "                                            preserve_range=True,\n",
    "                                            cval=0)\n",
    "    del init_cells\n",
    "    return scaled_init\n",
    "\n",
    "def get_t_eval(pov_ind, frames=np.arange(5,41)):\n",
    "    return pad_times_df.loc[pad_times_df.pad==pov_ind,'time'].values\n",
    "\n",
    "def pov_0_slices(n_h, n_w, s_h, s_w, scale):\n",
    "    y0, x0 = (np.array((n_h, n_w))//2) - np.array((s_h, s_w))//2\n",
    "    y1, x1 = np.array((y0,x0)) + np.array((s_h, s_w))\n",
    "    return slice(y0,y1), slice(x0,x1)\n",
    "\n",
    "def pov_1_slices(n_h, n_w, s_h, s_w, scale):\n",
    "    y0, x0 = (np.array((n_h, n_w))//2) - np.array((s_h, s_w))//2\n",
    "    y1, x1 = np.array((y0,x0)) + np.array((s_h, s_w))\n",
    "    return slice(y0,y1), slice(x0,x1)\n",
    "\n",
    "def pov_2_slices(n_h, n_w, s_h, s_w, scale):\n",
    "    y0, x0 = (np.array((n_h, n_w))//2) - np.array((s_h, s_w))//2\n",
    "    y1, x1 = np.array((y0,x0)) + np.array((s_h, s_w))\n",
    "    return slice(y0,y1), slice(x0,x1)\n",
    "\n",
    "def pov_4_slices(n_h, n_w, s_h, s_w, scale):\n",
    "    y0, x0 = (np.array((n_h, n_w))//2) - np.array((s_h, s_w))//2\n",
    "    y1, x1 = np.array((y0,x0)) + np.array((s_h, s_w))\n",
    "    return slice(y0,y1), slice(x0,x1)\n",
    "\n",
    "def pov_5_slices(n_h, n_w, s_h, s_w, scale):\n",
    "    y0, x0 = np.array(((n_h-s_h)//2, scale//8))\n",
    "    y1, x1 = np.array((y0,x0)) + np.array((s_h, s_w))\n",
    "    return slice(y0,y1), slice(x0,x1)\n",
    "\n",
    "def pov_6_slices(n_h, n_w, s_h, s_w, scale):\n",
    "    y0, x0 = np.array(((n_h-s_h)//2, 6*n_w//8))\n",
    "    y1, x1 = np.array((y0,x0)) + np.array((s_h, s_w))\n",
    "    return slice(y0,y1), slice(x0,x1)\n",
    "\n",
    "def pov_7_slices(n_h, n_w, s_h, s_w, scale):\n",
    "    y0, x0 = np.array(((n_h-s_h)//2, scale//2))\n",
    "    y1, x1 = np.array((y0,x0)) + np.array((s_h, s_w))\n",
    "    return slice(y0,y1), slice(x0,x1)\n",
    "\n",
    "def pov_8_slices(n_h, n_w, s_h, s_w, scale):\n",
    "    y0, x0 = np.array(((n_h-s_h)//2, (n_w-s_w)//2))\n",
    "    y1, x1 = np.array((y0,x0)) + np.array((s_h, s_w))\n",
    "    return slice(y0,y1), slice(x0,x1)\n",
    "\n",
    "def pov_9_slices(n_h, n_w, s_h, s_w, scale):\n",
    "    y0, x0 = np.array(((n_h-s_h)//2, (n_w-s_w)//2))\n",
    "    y1, x1 = np.array((y0,x0)) + np.array((s_h, s_w))\n",
    "    return slice(y0,y1), slice(x0,x1)\n",
    "            \n",
    "def pov_10_slices(n_h, n_w, s_h, s_w, scale):\n",
    "    y0, x0 = (np.array((0, n_w-s_w))//2)\n",
    "    y1, x1 = np.array((y0,x0)) + np.array((s_h, s_w))\n",
    "    return slice(y0,y1), slice(x0,x1)\n",
    "\n",
    "\n",
    "class PrepPad(object):\n",
    "    '''\n",
    "    Prepares initial conditions for solve_ivp and facilitates comparisons of experimental data to simulation.  \n",
    "    \n",
    "    This class is defined according to a specific experiment. The pad dimensions and imaging locations are\n",
    "    defined for each experimental pad in the __init__ function. Passing a scale and pad index parameter\n",
    "    to the constructor \n",
    "    '''\n",
    "    def get_time_vec(self):\n",
    "        return get_t_eval(self.pov_inds[0])\n",
    "    \n",
    "    def get_fn_lists(self, frames=np.arange(5,41)):\n",
    "        mask_fn_tmpl = 'worker_outputs/initial_frame_masks/pad_{}_frame_{}.tif'\n",
    "        fn_format = lambda pov, frame : mask_fn_tmpl.format(pov, frame)\n",
    "        fn_lists = [[fn_format(pov, frame) for frame in frames] for pov in self.pov_inds]\n",
    "        return dict(zip(self.pov_inds, fn_lists))\n",
    "    \n",
    "    def prep_initial_cell(self):\n",
    "        n_h, n_w = self.cell_init.shape\n",
    "        if np.any(self.cell_init!=0):\n",
    "            self.cell_init[:] = 0\n",
    "        for pov_ind, slice_fun in zip(self.pov_inds, self.slice_functions):\n",
    "            scaled_init = prep_pad_helper(self.scale, pov_ind, 5)\n",
    "            s_h, s_w = scaled_init.shape\n",
    "            yslice, xslice = slice_fun(n_h, n_w, s_h, s_w, self.scale)\n",
    "            self.cell_init[yslice, xslice] += scaled_init\n",
    "            \n",
    "            \n",
    "    def __init__(self, scale, pad_ind):\n",
    "        self.scale = scale\n",
    "        if pad_ind==0:\n",
    "            n_h, n_w = (2*scale, 2*scale)\n",
    "            self.cell_init = np.zeros((n_h, n_w), dtype=np.float32)        \n",
    "            self.pad = 0\n",
    "            self.pov_inds = [0]\n",
    "            self.slice_functions = [pov_0_slices]\n",
    "        \n",
    "        elif pad_ind==1:\n",
    "            n_h, n_w = (2*scale, 2*scale)\n",
    "            self.cell_init = np.zeros((n_h, n_w), dtype=np.float32)        \n",
    "            self.pad = 1\n",
    "            self.pov_inds = [1, 10]\n",
    "            self.slice_functions = [pov_1_slices, pov_10_slices]\n",
    "            \n",
    "        elif pad_ind==2:\n",
    "            n_h, n_w = (2*scale, 2*scale)\n",
    "            self.cell_init = np.zeros((n_h, n_w), dtype=np.float32)\n",
    "            self.pad = 2\n",
    "            self.pov_inds = [2]\n",
    "            self.slice_functions = [pov_2_slices]\n",
    "\n",
    "        elif pad_ind==4:\n",
    "            n_h, n_w = (3*scale, 3*scale)\n",
    "            self.cell_init = np.zeros((n_h, n_w), dtype=np.float32)\n",
    "            self.pad = 4\n",
    "            self.pov_inds = [4]\n",
    "            self.slice_functions = [pov_4_slices]\n",
    "\n",
    "        elif pad_ind==5:\n",
    "            n_h, n_w = (5*scale, 5*scale)\n",
    "            self.cell_init = np.zeros((n_h, n_w), dtype=np.float32)\n",
    "            self.pad = 5\n",
    "            self.pov_inds = [5,6]\n",
    "            self.slice_functions = [pov_5_slices, pov_6_slices]\n",
    "            \n",
    "        elif pad_ind==6:\n",
    "            n_h, n_w = (5*scale, 5*scale)\n",
    "            self.cell_init = np.zeros((n_h, n_w), dtype=np.float32)\n",
    "            self.pad = 6\n",
    "            self.pov_inds = [7]\n",
    "            self.slice_functions = [pov_7_slices]\n",
    "\n",
    "        elif pad_ind==7:\n",
    "            n_h, n_w = (3*scale, 3*scale)\n",
    "            self.cell_init = np.zeros((n_h, n_w), dtype=np.float32)\n",
    "            self.pad = 7\n",
    "            self.pov_inds = [8]\n",
    "            self.slice_functions = [pov_8_slices]\n",
    "\n",
    "        elif pad_ind==8:\n",
    "            n_h, n_w = (2*scale, 2*scale)\n",
    "            self.cell_init = np.zeros((n_h, n_w), dtype=np.float32)\n",
    "            self.pad = 8\n",
    "            self.pov_inds = [9]\n",
    "            self.slice_functions = [pov_9_slices]\n",
    "            \n",
    "        else:\n",
    "            raise ValueError\n",
    "        \n",
    "        self.prep_initial_cell()\n",
    "    \n",
    "\n",
    "# try to make a jacobian function\n",
    "# you'll likely need to use the vectorized version of the ODE, rather than the matrix version. \n",
    "# first, just see if you can use the sparsity structure matrix approach\n",
    "class Jacobian(object):\n",
    "    \n",
    "    def f_ji(self, x, y, spec):\n",
    "        _, n_h, n_w, _ = self.dims\n",
    "        return x + n_w*y + n_w*n_h*spec\n",
    "    \n",
    "    def __init__(self, dims):\n",
    "        species, n_h, n_w, scale = dims\n",
    "        self.dims = dims\n",
    "        self.dx = np.power(scale/4.5,2)\n",
    "        c_i, n_i = np.arange(species)\n",
    "        # Make jacobian array\n",
    "        n_jac = n_h*n_w*species\n",
    "        # jacobian terms:\n",
    "        # diffusion : 5 per x,y point, minus \n",
    "        n_nz = n_jac*5 - 2*(n_h+n_w)*species # + 4*n_h*n_w\n",
    "        self.dif_vec = np.empty(n_nz,dtype=np.float32)\n",
    "        self.j1_dif = np.empty(n_nz,dtype=np.int)\n",
    "        self.j2_dif = np.empty(n_nz,dtype=np.int)\n",
    "        \n",
    "        offsets = ((0,1), (1,0), (0,-1), (-1,0))\n",
    "        neigh_diff_indices = [[(self.f_ji(x,y,spec), self.f_ji(x+offx,y+offy,spec)) \n",
    "                                   for offy, offx in offsets\n",
    "                                    for x in np.arange(max([0,-offx]), n_w+min([0,-offx])) \n",
    "                                     for y in np.arange(max([0,-offy]), n_h+min([0,-offy]))]\n",
    "                                          for spec in np.arange(species)]\n",
    "        \n",
    "        center_diff_indices = [[(self.f_ji(x,y,spec), self.f_ji(x,y,spec)) \n",
    "                                for x in np.arange(1,n_w-1) \n",
    "                                 for y in np.arange(1,n_h-1)]\n",
    "                                   for spec in np.arange(species)]\n",
    "        \n",
    "        \n",
    "        edge_diff_indices = [[(self.f_ji(x,y,spec), self.f_ji(x,y,spec)) \n",
    "                                for x in np.arange(1,n_w-1) \n",
    "                                 for y in [0, n_h-1]] + \n",
    "                              [(self.f_ji(x,y,spec), self.f_ji(x,y,spec)) \n",
    "                                for x in [0,n_w-1] \n",
    "                                 for y in np.arange(1,n_h-1)]\n",
    "                                   for spec in np.arange(species)]\n",
    "        \n",
    "        corner_diff_indices = [[(self.f_ji(x,y,spec), self.f_ji(x,y,spec)) \n",
    "                                                    for x in [0,n_w-1] \n",
    "                                                     for y in [0,n_h-1]]\n",
    "                                                       for spec in np.arange(species)]\n",
    "        \n",
    "        self.dif_indices_list = [neigh_diff_indices, center_diff_indices, edge_diff_indices, corner_diff_indices]\n",
    "        \n",
    "        #dc/(dcdt)\n",
    "        dcdcdt_indices = [(x, y, self.f_ji(x,y,c_i), self.f_ji(x,y,c_i)) for x in np.arange(n_w) for y in np.arange(n_h)]\n",
    "\n",
    "        #dc/(dndt)\n",
    "        dcdndt_indices = [(x, y, self.f_ji(x,y,c_i), self.f_ji(x,y,n_i)) for x in np.arange(n_w) for y in np.arange(n_h)]\n",
    "\n",
    "        #dn/(dndt)\n",
    "        dndndt_indices = [(x, y, self.f_ji(x,y,n_i), self.f_ji(x,y,n_i)) for x in np.arange(n_w) for y in np.arange(n_h)]\n",
    "\n",
    "        #dn/(dcdt)\n",
    "        dndcdt_indices = [(x, y, self.f_ji(x,y,n_i), self.f_ji(x,y,c_i)) for x in np.arange(n_w) for y in np.arange(n_h)]\n",
    "\n",
    "        self.rxn_indices_list = [dcdcdt_indices, dcdndt_indices, dndndt_indices, dndcdt_indices]\n",
    "        n_terms = np.sum([len(xx) for xx in self.rxn_indices_list])\n",
    "        self.rxn_vec = np.zeros(n_terms, dtype=np.float32)\n",
    "        self.j1_rxn = np.zeros(n_terms, dtype=np.int)\n",
    "        self.j2_rxn = np.zeros(n_terms, dtype=np.int)\n",
    "\n",
    "    def set_p0(self, p0):\n",
    "        self.p0 = p0\n",
    "        Dc, Dn, rc, Kn, Hn, pn = p0\n",
    "        self.D_vec = [Dc, Dn]\n",
    "        self.calc_dif_jac()\n",
    "        \n",
    "    def assign_rxn_vals(self, indices, val_arr, i):\n",
    "        x1,y1,j1,j2 = np.array(indices).T\n",
    "        n_inds = len(x1)\n",
    "        update_slice = slice(i,i+n_inds)\n",
    "        self.rxn_vec[update_slice] = val_arr[y1,x1]\n",
    "        self.j1_rxn[update_slice] = j1\n",
    "        self.j2_rxn[update_slice] = j2\n",
    "        return i+n_inds\n",
    "    \n",
    "    def assign_dif_vals(self, val, ind_list, i):\n",
    "        n_inds = len(ind_list)\n",
    "        update_slice = slice(i,i+n_inds)\n",
    "        self.dif_vec[update_slice] = val\n",
    "        ij_arr = np.array(ind_list)\n",
    "        self.j1_dif[update_slice] = ij_arr[:,0]\n",
    "        self.j2_dif[update_slice] = ij_arr[:,1]\n",
    "        return i + n_inds\n",
    "        \n",
    "    def calc_dif_jac(self):\n",
    "        Dc, Dn, rc, Kn, Hn, pn = self.p0\n",
    "        D_vec = np.array(self.D_vec)\n",
    "        dx = self.dx\n",
    "        species, n_h, n_w, scale = self.dims\n",
    "        c_i, n_i = np.arange(species)\n",
    "        i = 0\n",
    "        neigh_diff_indices, center_diff_indices, edge_diff_indices, corner_diff_indices = self.dif_indices_list\n",
    "        val_arr = D_vec*dx\n",
    "        for val, ind_list in zip(val_arr, neigh_diff_indices):\n",
    "            i = self.assign_dif_vals(val, ind_list, i)\n",
    "        \n",
    "        val_arr = D_vec*(-4*dx)\n",
    "        for val, ind_list in zip(val_arr, center_diff_indices):\n",
    "            i = self.assign_dif_vals(val, ind_list, i)\n",
    "        \n",
    "        val_arr = D_vec*(-3*dx)\n",
    "        for val, ind_list in zip(val_arr, edge_diff_indices):\n",
    "            i = self.assign_dif_vals(val, ind_list, i)\n",
    "            \n",
    "        val_arr = D_vec*(-2*dx)\n",
    "        for val, ind_list in zip(val_arr, corner_diff_indices):\n",
    "            i = self.assign_dif_vals(val, ind_list, i)\n",
    "            \n",
    "    def calc_rxn_jac(self, t, y):\n",
    "        Dc, Dn, rc, Kn, Hn, pn = self.p0\n",
    "        dcdcdt_indices, dcdndt_indices, dndndt_indices, dndcdt_indices = self.rxn_indices_list\n",
    "        c_i, n_i = 0,1\n",
    "        \n",
    "        i = 0\n",
    "        #dc/(dcdt)\n",
    "        nut_avail = hill(y[n_i,:,:], Hn, Kn)\n",
    "        dnut_avail = dhillda(y[n_i,:,:], Hn, Kn)\n",
    "        val_arr = rc*nut_avail\n",
    "        i = self.assign_rxn_vals(dcdcdt_indices, val_arr,i)\n",
    "\n",
    "        #dc/(dndt)\n",
    "        val_arr = rc*dnut_avail*y[c_i,:,:]\n",
    "        i = self.assign_rxn_vals(dcdcdt_indices, val_arr,i)\n",
    "\n",
    "        #dn/(dndt)\n",
    "        val_arr = -pn*dnut_avail*y[c_i,:,:]\n",
    "        i = self.assign_rxn_vals(dcdcdt_indices, val_arr,i)\n",
    "\n",
    "        #dn/(dcdt)\n",
    "        val_arr = -pn*nut_avail\n",
    "        i = self.assign_rxn_vals(dcdcdt_indices, val_arr,i)\n",
    "\n",
    "    #     @numba.jit(cache=True)\n",
    "    def calc_jac_wrapper(self, t, y):\n",
    "        species, n_h, n_w, scale = self.dims\n",
    "        y.shape = (species,n_h,n_w)\n",
    "        n_jac = species*n_h*n_w\n",
    "        self.calc_rxn_jac(t,y)\n",
    "        data_vec = np.concatenate([self.dif_vec, self.rxn_vec])\n",
    "        j1_vec = np.concatenate([self.j1_dif, self.j1_rxn])\n",
    "        j2_vec = np.concatenate([self.j2_dif, self.j2_rxn])\n",
    "        y.shape = species*n_h*n_w\n",
    "        return sparse.coo_matrix((data_vec, (j1_vec,j2_vec)),shape=(n_jac, n_jac),dtype=np.float32)\n",
    "\n",
    "\n",
    "def prep_initial_array(species, cell_init):\n",
    "    c_i, n_i = np.arange(species)\n",
    "    col_thresh = 1e-4\n",
    "    n_h, n_w = cell_init.shape\n",
    "    # Set initial conditions\n",
    "    initial_array = np.zeros((species, n_h, n_w), dtype=np.float32, order='C')# + 1e-7\n",
    "    initial_array[n_i,:,:] = 100*np.ones((n_h, n_w), dtype=np.float32)\n",
    "    initial_array[c_i,:,:] = cell_init\n",
    "    return initial_array\n",
    "    \n",
    "def sim_pad_prep(scale, cell_init, t_eval):\n",
    "    species = 2 # cells, nutrients, mscarlet\n",
    "    n_h, n_w = cell_init.shape\n",
    "    initial_array = prep_initial_array(species, cell_init)\n",
    "    col_thresh = 1e-4\n",
    "    \n",
    "    dims = [species, n_h, n_w, scale]\n",
    "    c_i, n_i = np.arange(species)\n",
    "    \n",
    "    # Make empty array, and tolerance arrays\n",
    "    atol = np.zeros((species, n_h, n_w), dtype=np.float32,order='C')# + 1e-7\n",
    "    atol[c_i,:,:] = 1e-3*np.ones((n_h, n_w), dtype=np.float32)\n",
    "    atol[n_i,:,:] = 1e-2*np.ones((n_h, n_w), dtype=np.float32)\n",
    "    # atol must be a vector for the solver\n",
    "    atol.shape = species*n_h*n_w\n",
    "    rtol = 1e-3\n",
    "    \n",
    "    return dims, initial_array, t_eval, atol, rtol\n",
    "\n",
    "    \n",
    "@numba.jit(cache=True,nopython=True)\n",
    "def calc_f(y, d_y, diff_terms, nut_avail, p0):\n",
    "    dx, Dc, Dn, rc, Kn, Hn, pn = p0\n",
    "    calc_diffusion(y, diff_terms)\n",
    "\n",
    "    # Nutrient term\n",
    "    nut_avail[:,:] = hill(y[1,:,:], Hn, Kn)\n",
    "\n",
    "    # Cell growth and diffusion\n",
    "    d_y[0,:,:] = (dx)*Dc*diff_terms[0,:,:] + rc * nut_avail * y[0,:,:]\n",
    "\n",
    "    # Nutrient consumption\n",
    "    d_y[1,:,:] = (dx)*Dn*diff_terms[1,:,:] - pn * nut_avail * y[0,:,:]\n",
    "\n",
    "def sim_pad(p0, scale, prep_fn):\n",
    "    return wrapper(*sim_pad_prep(p0, scale, prep_fn))\n",
    "\n",
    "class Simulator(object):\n",
    "    def __init__(self, pad_prep):\n",
    "        scale, cell_init, t_eval = pad_prep.scale, pad_prep.cell_init, pad_prep.get_time_vec()\n",
    "        dims, initial_array, t_eval, atol, rtol = sim_pad_prep(scale, cell_init, t_eval)\n",
    "        self.cell_init = cell_init\n",
    "        self.dims = dims\n",
    "        self.initial_array = initial_array\n",
    "        self.t_eval = t_eval\n",
    "        self.atol = atol\n",
    "        self.rtol = rtol\n",
    "        self.dx = np.power(scale/4.5,2)\n",
    "        self.scale = scale\n",
    "        self.pad = pad_prep.pad\n",
    "        self.pov_inds = pad_prep.pov_inds\n",
    "        self.fn_list = pad_prep.get_fn_lists()\n",
    "        self.slice_functions = pad_prep.slice_functions\n",
    "        self.jacobian = Jacobian(dims)\n",
    "        self.load_exp_data()\n",
    "            \n",
    "    def load_exp_data(self):\n",
    "        out_fn_tmpl = 'worker_outputs/downsampled_mask_arrs/pad{}_scale{}_exparr.tif'\n",
    "        self.exp_list = self.pov_inds.copy()\n",
    "        scale = np.log2(self.scale).astype(np.int)\n",
    "        for i, pad_ind in enumerate(self.pov_inds):\n",
    "            fn = out_fn_tmpl.format(pad_ind, scale)\n",
    "            if os.path.isfile(fn):\n",
    "                self.exp_list[i] = skimage.io.imread(fn)\n",
    "            else:\n",
    "                print('could not find '+fn)\n",
    "                im_arr = skimage.io.imread_collection(self.fn_list[pad_ind]).concatenate()>1\n",
    "                scale_factor = (4/2.475)*(self.scale/4500)\n",
    "                sf = np.int(1/scale_factor)\n",
    "                im_dwn = skimage.transform.rescale(im_arr.astype(np.float32),\n",
    "                                                   (1.0,scale_factor,scale_factor),\n",
    "                                                   order=0, \n",
    "                                                   mode='constant', \n",
    "                                                   multichannel=False,\n",
    "                                                   preserve_range=True,\n",
    "                                                   cval=0)\n",
    "                skimage.io.imsave(fn, im_dwn)\n",
    "                self.exp_list[i] = im_dwn\n",
    "        \n",
    "    def sim(self, p0):\n",
    "        self.p0 = p0\n",
    "        Dc, Dn, rc, Kn, Hn, pn = p0\n",
    "        params = np.array([self.dx, Dc, Dn, rc, Kn, Hn, pn])\n",
    "        self.jacobian.set_p0(p0)\n",
    "        sim_arr, sim_tvc = wrapper(self.dims, params, self.initial_array, self.t_eval, self.atol, self.rtol, \n",
    "                calc_f, self.jacobian.calc_jac_wrapper)\n",
    "        self.sim_arr, self.sim_tvc = sim_arr, sim_tvc\n",
    "    \n",
    "    def fit_fun(self, p0):\n",
    "        if np.any(p0<0):\n",
    "            return np.inf\n",
    "        self.sim(p0)\n",
    "        n_frames, _, n_h, n_w = self.sim_arr.shape\n",
    "        if n_frames != len(self.t_eval):\n",
    "            return np.inf\n",
    "        err_sum = 0\n",
    "        for exp_arr, slice_fun in zip(self.exp_list, self.slice_functions):\n",
    "            _, s_h, s_w = exp_arr.shape\n",
    "            yslice, xslice = slice_fun(n_h, n_w, s_h, s_w, self.scale)\n",
    "            err_sum += np.sum(np.power(exp_arr - self.sim_arr[:,0,yslice,xslice],2))\n",
    "        return err_sum\n",
    "    \n",
    "    def make_exp_movie(self):\n",
    "        n_h, n_w = self.cell_init.shape\n",
    "        n_frames = len(self.t_eval)\n",
    "        exp_arr = np.zeros((n_frames, n_h, n_w))\n",
    "        for col_arr, slice_fun in zip(self.exp_list, self.slice_functions):\n",
    "            _, s_h, s_w = col_arr.shape\n",
    "            yslice, xslice = slice_fun(n_h, n_w, s_h, s_w, self.scale)\n",
    "            exp_arr[:,yslice,xslice] = col_arr\n",
    "        return exp_arr\n",
    "\n",
    "def logprior(p0):\n",
    "    from scipy.stats import cauchy\n",
    "    if np.any(p0<0):\n",
    "        return -np.inf\n",
    "    Dn, rc, Kn, Hn, pn = p0\n",
    "    if np.any(np.array([Dn,rc,Kn,Hn,pn])==0):\n",
    "        return -np.inf\n",
    "    val = 0\n",
    "    # Dn is jeffrey's\n",
    "    if Dn > 1e-3 or Dn < 1e-6:\n",
    "        return -np.inf\n",
    "    val += (-1/2)*np.log(Dn)\n",
    "    # rc under normal distribution (logged here) from 1e-4 to 5e-4\n",
    "#     if rc > 4e-4 or rc < 1e-4:\n",
    "#         return -np.inf\n",
    "#     val += (-1/2)*np.log(rc)\n",
    "    cauchy_params = (0.00022759430504618882, 1.8699032413798176e-05)\n",
    "    val += cauchy.logpdf(rc, *cauchy_params)\n",
    "    # Kn uniform between 0 and 100 (maybe change this for appearance's sake)\n",
    "    if Kn>100 or Kn<20:\n",
    "        val -= np.inf\n",
    "    # Hn uniform between 0.8 and 20\n",
    "    if Hn > 20 or Hn < 0.5:\n",
    "        val -= np.inf\n",
    "    # pn is jeffrey's\n",
    "    if pn > 1:\n",
    "        return -np.inf\n",
    "    val += (-1/2)*np.log(pn)\n",
    "    return val\n",
    "\n",
    "def fit_wrapper(arg):\n",
    "    sim_list, p0 = arg\n",
    "    return np.sum([xx.fit_fun(p0) for xx in sim_list])\n",
    "\n",
    "class Fitter(object):\n",
    "    def __init__(self, scale_exp, pad_inds):\n",
    "        self.scale = np.power(2,scale_exp)\n",
    "        n_pads = len(pad_inds)\n",
    "        preppad_inputs = zip(n_pads*[self.scale], pad_inds)\n",
    "        with Pool() as pool:\n",
    "            self.pad_list = pool.starmap(PrepPad, preppad_inputs)\n",
    "            self.sim_list = pool.map(Simulator, self.pad_list)\n",
    "#         _ = [xx.load_exp_data() for xx in self.sim_list]\n",
    "    \n",
    "    def resfun(self, psub):\n",
    "        Dn, rc, Kn, Hn, pn = psub\n",
    "        Dc = 1e-9\n",
    "        p0 = np.array([Dc, Dn, rc, Kn, Hn, pn])\n",
    "        logprior_val = logprior(psub)\n",
    "        if logprior_val == -np.inf:\n",
    "            return logprior_val\n",
    "        return self.loglikelihood(p0) + logprior_val\n",
    "\n",
    "    def par_loglikelihood(self, p0):\n",
    "        n_proc = np.min([cpu_count(), len(self.sim_list)])\n",
    "        sim_divisions = [self.sim_list[i::n_proc] for i in np.arange(n_proc)]\n",
    "        p0_list = n_proc*[p0]\n",
    "        with Pool(n_proc) as p:\n",
    "            residuals = np.sum(p.map(fit_wrapper, zip(sim_divisions, p0_list)))\n",
    "        res_std = 0.1\n",
    "        return -1*(1/2)*residuals/res_std**2\n",
    "    \n",
    "    def loglikelihood(self, p0):\n",
    "        n_proc = np.min([cpu_count(), len(self.sim_list)])\n",
    "        sim_divisions = [self.sim_list[i::n_proc] for i in np.arange(n_proc)]\n",
    "        p0_list = n_proc*[p0]\n",
    "        residuals = np.sum(list(map(fit_wrapper, zip(sim_divisions, p0_list))))\n",
    "        res_std = 0.1\n",
    "        return -1*(1/2)*residuals/res_std**2\n",
    "    \n",
    "    def par_resfun(self, psub):\n",
    "        Dn, rc, Kn, Hn, pn = psub\n",
    "        Dc = 1e-9\n",
    "        p0 = np.array([Dc, Dn, rc, Kn, Hn, pn])\n",
    "        logprior_val = logprior(psub)\n",
    "        if logprior_val == -np.inf:\n",
    "            return logprior_val\n",
    "        return self.par_loglikelihood(p0) + logprior_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmp/anaconda3/lib/python3.7/site-packages/emcee-3.0rc2-py3.7.egg/emcee/moves/red_blue.py:97: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# Get prior-distributed parameters\n",
    "if True:\n",
    "    nwalkers = 10\n",
    "    ndim = 5\n",
    "    nsteps = 10000\n",
    "    Dn_vals = np.power(10,np.linspace(-5.9,-2.9,nwalkers))\n",
    "    rc_vals = np.linspace(1.1e-4,2.9e-4,nwalkers)\n",
    "    Kn_vals = np.linspace(21,99,nwalkers)\n",
    "    Hn_vals = np.linspace(0.6, 19, nwalkers)\n",
    "    pn_vals = np.power(np.linspace(1.2e-4,1.4,nwalkers),2)\n",
    "    pos = np.array([np.random.choice(Dn_vals, nwalkers), \n",
    "                    np.random.choice(rc_vals, nwalkers), \n",
    "                    np.random.choice(Kn_vals, nwalkers), \n",
    "                    np.random.choice(Hn_vals, nwalkers), \n",
    "                    np.random.choice(pn_vals, nwalkers)]).T\n",
    "    nwalkers, ndim = pos.shape\n",
    "    with Pool() as pool:\n",
    "        sampler = emcee.EnsembleSampler(nwalkers, ndim, logprior, pool=pool)\n",
    "        sampler.run_mcmc(pos, nsteps);\n",
    "    flatchain = np.reshape(sampler.get_chain()[1000:,:,:].copy(),(nwalkers*(nsteps-1000),ndim),order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_exp = 4\n",
    "pad_list = [0,2,4,8]\n",
    "fitter = Fitter(scale_exp, pad_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Setup MCMC from prior-distributed parameters\n",
    "datecode = '190907'\n",
    "save_tmpl = 'worker_outputs/pool_outputs/long_run_emcee_{}.csv'\n",
    "save_file = save_tmpl.format(datecode)\n",
    "nwalkers = 10\n",
    "ndim = 5\n",
    "nsteps = 2\n",
    "if True:\n",
    "    post_pos = flatchain[np.random.choice(np.arange(flatchain.shape[0]),nwalkers),:]\n",
    "    pd.DataFrame(pos).to_csv(save_file, header=False, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00:25:24 09/08/19'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "os.environ['TZ'] = 'PST+7'\n",
    "time.tzset()\n",
    "time.strftime('%X %x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    post_pos\n",
    "except NameError:\n",
    "    post_pos = pd.read_csv(save_file,header=None,index_col=0).values[-nwalkers:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmp/anaconda3/lib/python3.7/site-packages/scipy/integrate/_ivp/bdf.py:404: RuntimeWarning: invalid value encountered in subtract\n",
      "  D[order + 2] = d - D[order + 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 s, sys: 884 ms, total: 12.8 s\n",
      "Wall time: 38.3 s\n",
      "Updated at 00:26:03 09/08/19\n"
     ]
    }
   ],
   "source": [
    "# while True:\n",
    "# with Pool() as pool:\n",
    "post_sampler = emcee.EnsembleSampler(nwalkers, ndim, fitter.par_resfun)\n",
    "%time post_sampler.run_mcmc(post_pos, nsteps);\n",
    "post_flatchain = post_sampler.get_chain(flat=True)\n",
    "pd.DataFrame(post_flatchain).to_csv(save_file, header=False, mode='a')\n",
    "print('Updated at {}'.format(time.strftime('%X %x')))\n",
    "post_pos = post_sampler.get_chain()[-1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.3 s, sys: 88.3 ms, total: 19.4 s\n",
      "Wall time: 28.8 s\n",
      "Updated at 00:26:47 09/08/19\n"
     ]
    }
   ],
   "source": [
    "# while True:\n",
    "with Pool() as pool:\n",
    "    post_sampler = emcee.EnsembleSampler(nwalkers, ndim, fitter.resfun,pool=pool)\n",
    "    %time post_sampler.run_mcmc(post_pos, nsteps);\n",
    "post_flatchain = post_sampler.get_chain(flat=True)\n",
    "pd.DataFrame(post_flatchain).to_csv(save_file, header=False, mode='a')\n",
    "print('Updated at {}'.format(time.strftime('%X %x')))\n",
    "post_pos = post_sampler.get_chain()[-1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
